---
title: TGF Data Dive
date: 2022-03-19
tags: ['experiments', 'tech', 'dataviz', 'parkrun']
socialImage: '../images/post-images/parkrun1.jpg'
postImages:
  - '../images/post-images/parkrun1.jpg'
  - '../images/post-images/parkrun2.jpg'
  - '../images/post-images/parkrun3.jpg'
---

import { getImage, GatsbyImage } from 'gatsby-plugin-image'
import Barchart from '../components/charts/barchart'
import Linechart from '../components/charts/linechart'

The folks who follow [me on twitter](https://twitter.com/_disco) will have possibly noticed that parkrun has become a bit of an obsession for me lately. There are a few reasons for this which I'm sure i'll write about another day. The short story though is that I'm currently loving it and in my spare time i'm part of the core event team for [The Great Field parkrun](https://www.parkrun.org.uk/thegreatfield/) which is conveniently just a few mins walk from my front door in Poundbury, Dorset.

This week I decided it'd be an interesting exercise to pull together some of our event data to see what I could learn about our little community event so far. For context i'm no crack data scientist or analyst but thought it'd be an interesting challenge for me to blow the cobwebs off my limited skills and share some of what I found. If the 'how I did this' bit doesn't interest you feel free to [skip down to the insights](#insights).

## Method

Glancing through the the stats on the parkrun website confirmed by suspcisions that the data volume for just my local event wouldn't be sizeable enough (yet) to mean that I'd need anything too complex in terms of tools to understand the data. Just getting all of the results into a single spreadsheet would be the simplest and most accessible way for me (and anybody else who might be interested) to start to doing basic analysis.

The parkrun fairies do an amazing job of making sure results from every event across the globe are published in table form on the website every week and I started by just copying and pasting these into google sheets. It soon became a chore to try and tidy up and clean the HTML elements to get things in the right place and it certainly didn't feel something I'd want to repeat very often.

Some basic research around available [parkrun APIs](https://developer.parkrun.com/) were a bit hit and miss. Plans for anything official look like they had been shelved a while back (which is sad but also understandable). The nerdier elements of the parkrun community (there are lots of us) have seemingly tried to fill these gaps over time by creating many things in this space but many were outdated, poorly documented. [Some seem promising](https://parkrun.js.org/index.html) but added more complexity than I wanted to consider right now.

I decided a suitable compromise would be to use my web browser to [save local copies](https://www.dummies.com/article/technology/internet-basics/how-to-save-a-web-page-in-google-chrome-140687]) of the 20 event results pages into a folder and then create a script to make the process of extracting the data and adding it to a single spreadsheet friendly file of comma seperated values(csv) a little less tedious. I will keep looking into some of these other aproaches/tools though as there are limits baked into the results pages that are limiting (like not understanding more about volunteers on the day, and knowing an athletes 'home' parkrun).

Given I am not a developer and that I've never done this before the process of creating the script involved more than a little bit of trial and error, lots of googling and some swearing but what I've written works! The resulting script means I can now easily append my dataset with new results every week with a couple of clicks. I could likely also automate this part of the process but that's an experiment for another day. The script itself with a short README file is [available on github](https://github.com/d1sc0/tgf-parkrun-stats) if you have [node](https://nodejs.org/en/) running on your computer, have a bias for hacking things together and want to achieve something similar. For any readers who can write code properly, please be kind - I was born before the internet! :boom:

In terms of creating the graphs included on this page I've used a react library called [react-chartjs-2](https://www.npmjs.com/package/react-chartjs-2) to present the data as chart components embedded into this [mdx](https://mdxjs.com/) formatted post on my [Gatsby blog](https://www.gatsbyjs.com/). Screenshots of graphs from the spreadsheet would have also been fine...but far less satisfying for my inner geek.

<Linechart />

## Insights <a id="insights"></a>

### 20 event summary (numbers, particpants, stalwarts, distance covered)

### Attendance (distribution age, sex, clubs)

### Times/performance (fastest, slowest, average times over events, distribution of runners by 5 min chunks? number of walkers)

###
